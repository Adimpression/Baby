When cloned and persisted Human, Datanuclues gave the following exceptions:

javax.ejb.EJBException: The bean encountered a non-application exception; nested exception is:
	javax.ejb.EJBTransactionRolledbackException: The transaction has been marked rollback only because the bean encountered a non-application exception :org.apache.openjpa.util.InvalidStateException : Detected reentrant flush.  Make sure your flush-time instance callback methods or event listeners do not invoke any operations that require the in-progress flush to complete.
	at org.apache.openejb.core.ivm.BaseEjbProxyHandler.convertException(BaseEjbProxyHandler.java:359) [openejb-core-3.1.4.jar:3.1.4]
	at org.apache.openejb.core.ivm.BaseEjbProxyHandler.invoke(BaseEjbProxyHandler.java:287) [openejb-core-3.1.4.jar:3.1.4]
	at $Proxy118.doNTxCHuman(Unknown Source) [na:na]


Caused by: org.apache.openjpa.util.InvalidStateException: Detected reentrant flush.  Make sure your flush-time instance callback methods or event listeners do not invoke any operations that require the in-progress flush to complete.
	at org.apache.openjpa.kernel.BrokerImpl.flushSafe(BrokerImpl.java:1904) [openjpa-1.2.1.jar:1.2.1]
	at org.apache.openjpa.kernel.BrokerImpl.flush(BrokerImpl.java:1679) [openjpa-1.2.1.jar:1.2.1]
	at org.apache.openjpa.kernel.DetachManager.flushDirty(DetachManager.java:227) [openjpa-1.2.1.jar:1.2.1]
	at org.apache.openjpa.kernel.DetachManager.preSerialize(DetachManager.java:88) [openjpa-1.2.1.jar:1.2.1]
	at org.apache.openjpa.kernel.StateManagerImpl.serializing(StateManagerImpl.java:1353) [openjpa-1.2.1.jar:1.2.1]
	at ai.ilikeplaces.entities.HumansPrivatePhoto.pcSerializing(HumansPrivatePhoto.java) [HumansPrivatePhoto.class:na]
	at ai.ilikeplaces.entities.HumansPrivatePhoto.writeObject(HumansPrivatePhoto.java) [HumansPrivatePhoto.class:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) [na:1.6.0_24]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) [na:1.6.0_24]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) [na:1.6.0_24]
	at java.lang.reflect.Method.invoke(Method.java:616) [na:1.6.0_24]
	at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:959) [na:1.6.0_24]
	at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1480) [na:1.6.0_24]
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1416) [na:1.6.0_24]
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1174) [na:1.6.0_24]
	at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1528) [na:1.6.0_24]
	at java.io.ObjectOutputStream.defaultWriteObject(ObjectOutputStream.java:438) [na:1.6.0_24]
	at ai.ilikeplaces.entities.Human.writeObject(Human.java) [Human.class:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) [na:1.6.0_24]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) [na:1.6.0_24]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) [na:1.6.0_24]
	at java.lang.reflect.Method.invoke(Method.java:616) [na:1.6.0_24]
	at java.io.ObjectStreamClass.invokeWriteObject(ObjectStreamClass.java:959) [na:1.6.0_24]
	at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1480) [na:1.6.0_24]
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1416) [na:1.6.0_24]
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1174) [na:1.6.0_24]
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:346) [na:1.6.0_24]
	at ai.ilikeplaces.entities.Human.clone(Human.java:236) [Human.class:na]
	at ai.ilikeplaces.entities.NSHuman.postPersist(NSHuman.java:22) [NSHuman.class:na]


////////////////////////////////////////////

We need to make the map store available on main classpath. NOTHING APPEARED ON LOGS. NO LOG ERRORS.
It is through the console that we found this.


hazelcast[default] > ns ai.ilikeplaces.entities.Human
namespace: ai.ilikeplaces.entities.Human
hazelcast[ai.ilikeplaces.entities.Human] > m.size
Jul 6, 2012 10:27:39 PM com.hazelcast.impl.CMap
SEVERE: /127.0.0.1:5701 [dev] ai.ilikeplaces.util.cache.HazelcastHumanMapStore
java.lang.ClassNotFoundException: ai.ilikeplaces.util.cache.HazelcastHumanMapStore
	at java.net.URLClassLoader$1.run(URLClassLoader.java:217)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:205)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:321)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:294)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:266)
	at com.hazelcast.nio.AbstractSerializer.loadClass(AbstractSerializer.java:85)
	at com.hazelcast.nio.Serializer.loadClass(Serializer.java:42)
	at com.hazelcast.impl.CMap.<init>(CMap.java:203)
	at com.hazelcast.impl.ConcurrentMapManager.getOrCreateMap(ConcurrentMapManager.java:2162)
	at com.hazelcast.impl.FactoryImpl.createProxy(FactoryImpl.java:735)
	at com.hazelcast.impl.FactoryImpl$7.process(FactoryImpl.java:809)
	at com.hazelcast.cluster.ClusterService$1.process(ClusterService.java:126)
	at com.hazelcast.cluster.ClusterService.processProcessable(ClusterService.java:190)
	at com.hazelcast.cluster.ClusterService.dequeueProcessables(ClusterService.java:256)
	at com.hazelcast.cluster.ClusterService.run(ClusterService.java:201)
	at java.lang.Thread.run(Thread.java:679)




################################################

Data getting persisted on HBase upon exciting clister Hazelcast. Probably hanling until then due to port configuration issue:


ls apache-tomcat-6.0.14/lib/
activation-1.1.jar                    GooglePlacesAPI-Client-1.0.jar
annotations-api.jar                   gson-1.7.2.jar
aopalliance-1.0.jar                   guice-2.0.jar
asm-commons-3.3.1.jar                 guice-assisted-inject-2.0.jar
batik-dom.jar                         hadoop-core-1.0.0.jar
batik-util.jar                        hazelcast-2.0.3.jar
batik-xml.jar                         hazelcast-client-2.0.3.jar
catalina-ant.jar                      hazelcast-mapstores.jar.bak
catalina-ha.jar                       hazelcast.xml
catalina.jar                          hbase-0.92.1.jar
catalina-tribes.jar                   hbase-site.xml
cloudfiles.properties                 ilikeplaces-doc-3.0.jar
commons-cli-1.1.jar                   ilikeplaces-entities.jar
commons-codec-1.2.jar                 ilikeplaces-util-4.0.jar
commons-codec-1.3.jar                 ilikeplaces-util-4.1.jar
commons-configuration-1.6.jar         ItsNat.jar
commons-fileupload-1.2.1.jar          jasper-el.jar
commons-httpclient-3.1.jar            jasper.jar
commons-io-1.4.jar                    jasper-jdt.jar
commons-lang-2.4.jar                  java-cloudfiles.jar
commons-logging-1.1.1.jar             jaxb-api-2.1.jar
datanucleus-api-jdo-3.0.2.jarb        jaxb-impl-2.1.9.jar
datanucleus-api-jdo-3.0.8.jar         jdo-api-3.0.jar
datanucleus-api-jdo-3.1.0-m2.jarb     jdo-api-3.1-SNAPSHOT-20120609.jar
datanucleus-api-jpa-3.0.11.jar        json-20090211.jar
datanucleus-api-jpa-3.0.2.jarb        jsp-api.jar
datanucleus-api-jpa-3.1.0-m2.jarb     jta-1.0.1B.jar
datanucleus-core-3.0.11.jar           jta-1.1.jar
datanucleus-core-3.0.2.jarb           jta-1.1-sources.jar
datanucleus-core-3.1.0-m4.jarb        log4j-1.2.15.jar
datanucleus-enhancer-2.1.3.jarb       log4j.properties
datanucleus-enhancer-3.1.0-m1.jar     logback-access-0.9.17.jar
datanucleus-hbase-2.0.0-release.jarb  logback-classic-0.9.17.jar
datanucleus-hbase-3.0.6.jar           logback-core-0.9.17.jar
datanucleus-jpa-2.1.8.jarb            mail-1.4.1.jar
datanucleus-rdbms-3.0.10.jar          nekohtml.jar
datanucleus-rdbms-3.0.2.jarb          oval-1.40.jar
datanucleus-rdbms-3.1.0-m4.jabr       runtime-0.4.1.5.jar
derbyclient.jar                       serializer.jar
DisqusAPI-Client-1.0.jar              servlet-api.jar
dn-openejb.jar                        session-1.0.1.jar
ehcache-core-2.5.2.jar                slf4j-api-1.5.8.jar
ehcache-openjpa-0.2.0.jar             stax-api-1.0-2.jar
ehcache.xml                           tomcat-coyote.jar
el-api.jar                            tomcat-dbcp.jar
facebook-java-api-3.0.4.jar           tomcat-i18n-es.jar
facebook-java-api-schema-3.0.4.jar    tomcat-i18n-fr.jar
gdata-client-1.0.jar                  tomcat-i18n-ja.jar
gdata-contacts-3.0.jar                transaction-api-1.1.jar
gdata-core-1.0.jar                    twitter4j-core-2.1.0.jar
geronimo-jpa_2.0_spec-1.0.jar         xercesImpl-2.8.1.jar
_GlobalConfig (copy).properties       xercesImpl.jar
_GlobalConfig.properties              xml-apis.jar
GlobalConfig.properties               YahooGeoPlanet-Client-1.0.jar
google-collect-1.0-rc1.jar            zookeeper-3.4.3.jar


java -cp openjpa-1.2.1.jar:ilikeplaces-classes.jar:slf4j-simple-1.4.2.jar:geronimo-jpa_2.0_spec-1.0.jar:asm-commons-3.3.1.jar:commons-fileupload-1.2.1.jar:datanucleus-enhancer-3.1.0-m1.jar:hazelcast.xml:serializer.jar:batik-dom.jar:commons-httpclient-3.1.jar:datanucleus-hbase-3.0.6.jar:hbase-0.92.1.jar:slf4j-api-1.5.8.jar:batik-util.jar:commons-io-1.4.jar:datanucleus-rdbms-3.0.10.jar:jdo-api-3.0.jar:transaction-api-1.1.jar:batik-xml.jar:commons-lang-2.4.jar:el-api.jar:jdo-api-3.1-SNAPSHOT-20120609.jar:xercesImpl-2.8.1.jar:commons-cli-1.1.jar:commons-logging-1.1.1.jar:hadoop-core-1.0.0.jar:jta-1.0.1B.jar:xercesImpl.jar:commons-codec-1.2.jar:datanucleus-api-jdo-3.0.8.jar:hazelcast-2.0.3.jar:jta-1.1.jar:xml-apis.jar:commons-codec-1.3.jar:datanucleus-api-jpa-3.0.11.jar:hazelcast-client-2.0.3.jar:log4j-1.2.15.jar:zookeeper-3.4.3.jar:commons-configuration-1.6.jar:datanucleus-core-3.0.11.jar:hazelcast-mapstores.jar:log4j.properties com.hazelcast.examples.TestApp
Better:

java -cp $(echo *.jar | tr ' ' ':'):hazelcast.xml:log4j.properties  com.hazelcast.examples.TestApp

If a NullPointerException(NPE) is thrown saying entityManger is null, this might be because the jars in the app are not deleted. i.e. they are already present in tomcats main lib folder.

DO NOT HAVE hazelcast_mapstore.jar on tomcat lib, will cause wierd exceptions.




There is no response for Call [2] operation=CONCURRENT_MAP_PUT

The above issue is fixed if write through value in hazelcast.xml > 0, i.e. delayed.

Put this on catalina.sh

JAVA_OPTS="-Dhazelcast.super.client=true"


Data Persistence Working With Errors On HBase Upon Updates.

hazelcast/hazelcast.xml:


<?xml version="1.0" encoding="UTF-8"?>
<!--
  ~ Copyright (c) 2008-2012, Hazel Bilisim Ltd. All Rights Reserved.
  ~
  ~ Licensed under the Apache License, Version 2.0 (the "License");
  ~ you may not use this file except in compliance with the License.
  ~ You may obtain a copy of the License at
  ~
  ~ http://www.apache.org/licenses/LICENSE-2.0
  ~
  ~ Unless required by applicable law or agreed to in writing, software
  ~ distributed under the License is distributed on an "AS IS" BASIS,
  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  ~ See the License for the specific language governing permissions and
  ~ limitations under the License.
  -->

<hazelcast xsi:schemaLocation="http://www.hazelcast.com/schema/config hazelcast-config-2.0.xsd"
           xmlns="http://www.hazelcast.com/schema/config"
           xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">
    <group>
        <name>dev</name>
        <password>dev-pass</password>
    </group>
    <management-center enabled="false">http://localhost:8080/mancenter</management-center>
    <network>
        <port auto-increment="true">5701</port>
        <join>
            <multicast enabled="false">
                <multicast-group>224.2.2.3</multicast-group>
                <multicast-port>54327</multicast-port>
            </multicast>
            <tcp-ip enabled="true">
                <interface>127.0.0.1</interface>
            </tcp-ip>
            <aws enabled="false">
                <access-key>my-access-key</access-key>
                <secret-key>my-secret-key</secret-key>
                <!--optional, default is us-east-1 -->
                <region>us-west-1</region>
                <!-- optional, only instances belonging to this group will be discovered, default will try all running instances -->
                <security-group-name>hazelcast-sg</security-group-name>
                <tag-key>type</tag-key>
                <tag-value>hz-nodes</tag-value>
            </aws>
        </join>
        <interfaces enabled="false">
            <interface>10.10.1.*</interface>
        </interfaces>
        <ssl enabled="false" />
        <socket-interceptor enabled="false" />
        <symmetric-encryption enabled="false">
            <!--
               encryption algorithm such as
               DES/ECB/PKCS5Padding,
               PBEWithMD5AndDES,
               AES/CBC/PKCS5Padding,
               Blowfish,
               DESede
            -->
            <algorithm>PBEWithMD5AndDES</algorithm>
            <!-- salt value to use when generating the secret key -->
            <salt>thesalt</salt>
            <!-- pass phrase to use when generating the secret key -->
            <password>thepass</password>
            <!-- iteration count to use when generating the secret key -->
            <iteration-count>19</iteration-count>
        </symmetric-encryption>
        <asymmetric-encryption enabled="false">
            <!-- encryption algorithm -->
            <algorithm>RSA/NONE/PKCS1PADDING</algorithm>
            <!-- private key password -->
            <keyPassword>thekeypass</keyPassword>
            <!-- private key alias -->
            <keyAlias>local</keyAlias>
            <!-- key store type -->
            <storeType>JKS</storeType>
            <!-- key store password -->
            <storePassword>thestorepass</storePassword>
            <!-- path to the key store -->
            <storePath>keystore</storePath>
        </asymmetric-encryption>
    </network>
    <partition-group enabled="false"/>

    <map name="ai.ilikeplaces.entities.Human">
        <map-store enabled="true">
            <class-name>ai.ilikeplaces.util.cache.HazelcastHumanMapStore</class-name>
            <write-delay-seconds>1</write-delay-seconds>
        </map-store>
    </map>




</hazelcast>





tomcat/lib/hazelcast.xml


<?xml version="1.0" encoding="UTF-8"?>
<!--
  ~ Copyright (c) 2008-2012, Hazel Bilisim Ltd. All Rights Reserved.
  ~
  ~ Licensed under the Apache License, Version 2.0 (the "License");
  ~ you may not use this file except in compliance with the License.
  ~ You may obtain a copy of the License at
  ~
  ~ http://www.apache.org/licenses/LICENSE-2.0
  ~
  ~ Unless required by applicable law or agreed to in writing, software
  ~ distributed under the License is distributed on an "AS IS" BASIS,
  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  ~ See the License for the specific language governing permissions and
  ~ limitations under the License.
  -->

<hazelcast xsi:schemaLocation="http://www.hazelcast.com/schema/config hazelcast-config-2.0.xsd"
           xmlns="http://www.hazelcast.com/schema/config"
           xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">
    <group>
        <name>dev</name>
        <password>dev-pass</password>
    </group>
    <management-center enabled="false">http://localhost:8080/mancenter</management-center>
    <network>
        <port auto-increment="true">5701</port>
        <join>
            <multicast enabled="false">
                <multicast-group>224.2.2.3</multicast-group>
                <multicast-port>54327</multicast-port>
            </multicast>
            <tcp-ip enabled="true">
                <interface>127.0.0.1</interface>
            </tcp-ip>
            <aws enabled="false">
                <access-key>my-access-key</access-key>
                <secret-key>my-secret-key</secret-key>
                <!--optional, default is us-east-1 -->
                <region>us-west-1</region>
                <!-- optional, only instances belonging to this group will be discovered, default will try all running instances -->
                <security-group-name>hazelcast-sg</security-group-name>
                <tag-key>type</tag-key>
                <tag-value>hz-nodes</tag-value>
            </aws>
        </join>
        <interfaces enabled="false">
            <interface>10.10.1.*</interface>
        </interfaces>
        <ssl enabled="false" />
        <socket-interceptor enabled="false" />
        <symmetric-encryption enabled="false">
            <!--
               encryption algorithm such as
               DES/ECB/PKCS5Padding,
               PBEWithMD5AndDES,
               AES/CBC/PKCS5Padding,
               Blowfish,
               DESede
            -->
            <algorithm>PBEWithMD5AndDES</algorithm>
            <!-- salt value to use when generating the secret key -->
            <salt>thesalt</salt>
            <!-- pass phrase to use when generating the secret key -->
            <password>thepass</password>
            <!-- iteration count to use when generating the secret key -->
            <iteration-count>19</iteration-count>
        </symmetric-encryption>
        <asymmetric-encryption enabled="false">
            <!-- encryption algorithm -->
            <algorithm>RSA/NONE/PKCS1PADDING</algorithm>
            <!-- private key password -->
            <keyPassword>thekeypass</keyPassword>
            <!-- private key alias -->
            <keyAlias>local</keyAlias>
            <!-- key store type -->
            <storeType>JKS</storeType>
            <!-- key store password -->
            <storePassword>thestorepass</storePassword>
            <!-- path to the key store -->
            <storePath>keystore</storePath>
        </asymmetric-encryption>
    </network>
    <partition-group enabled="false"/>
    <executor-service>
        <core-pool-size>16</core-pool-size>
        <max-pool-size>64</max-pool-size>
        <keep-alive-seconds>60</keep-alive-seconds>
    </executor-service>
    <queue name="default">
        <!--
            Maximum size of the queue. When a JVM's local queue size reaches the maximum,
            all put/offer operations will get blocked until the queue size
            of the JVM goes down below the maximum.
            Any integer between 0 and Integer.MAX_VALUE. 0 means
            Integer.MAX_VALUE. Default is 0.
        -->
        <max-size-per-jvm>0</max-size-per-jvm>
        <!--
            Name of the map configuration that will be used for the backing distributed
            map for this queue.
        -->
        <backing-map-ref>default</backing-map-ref>
    </queue>
    <map name="default">
        <!--
            Number of backups. If 1 is set as the backup-count for example,
            then all entries of the map will be copied to another JVM for
            fail-safety. 0 means no backup.
        -->
        <backup-count>1</backup-count>
        <!--
			Maximum number of seconds for each entry to stay in the map. Entries that are
			older than <time-to-live-seconds> and not updated for <time-to-live-seconds>
			will get automatically evicted from the map.
			Any integer between 0 and Integer.MAX_VALUE. 0 means infinite. Default is 0.
		-->
        <time-to-live-seconds>0</time-to-live-seconds>
        <!--
			Maximum number of seconds for each entry to stay idle in the map. Entries that are
			idle(not touched) for more than <max-idle-seconds> will get
			automatically evicted from the map. Entry is touched if get, put or containsKey is called.
			Any integer between 0 and Integer.MAX_VALUE. 0 means infinite. Default is 0.
		-->
        <max-idle-seconds>0</max-idle-seconds>
        <!--
            Valid values are:
            NONE (no eviction),
            LRU (Least Recently Used),
            LFU (Least Frequently Used).
            NONE is the default.
        -->
        <eviction-policy>NONE</eviction-policy>
        <!--
            Maximum size of the map. When max size is reached,
            map is evicted based on the policy defined.
            Any integer between 0 and Integer.MAX_VALUE. 0 means
            Integer.MAX_VALUE. Default is 0.
        -->
        <max-size policy="cluster_wide_map_size">0</max-size>
        <!--
            When max. size is reached, specified percentage of
            the map will be evicted. Any integer between 0 and 100.
            If 25 is set for example, 25% of the entries will
            get evicted.
        -->
        <eviction-percentage>25</eviction-percentage>
        <!--
            While recovering from split-brain (network partitioning),
            map entries in the small cluster will merge into the bigger cluster
            based on the policy set here. When an entry merge into the
            cluster, there might an existing entry with the same key already.
            Values of these entries might be different for that same key.
            Which value should be set for the key? Conflict is resolved by
            the policy set here. Default policy is hz.ADD_NEW_ENTRY

            There are built-in merge policies such as
            hz.NO_MERGE      ; no entry will merge.
            hz.ADD_NEW_ENTRY ; entry will be added if the merging entry's key
                               doesn't exist in the cluster.
            hz.HIGHER_HITS   ; entry with the higher hits wins.
            hz.LATEST_UPDATE ; entry with the latest update wins.
        -->
        <merge-policy>hz.ADD_NEW_ENTRY</merge-policy>
    </map>

    <map name="ai.ilikeplaces.entities.Human">
        <map-store enabled="true">
            <class-name>ai.ilikeplaces.util.cache.HazelcastHumanMapStore</class-name>
            <write-delay-seconds>1</write-delay-seconds>
        </map-store>
    </map>

    <!-- Add your own semaphore configurations here:
        <semaphore name="default">
            <initial-permits>10</initial-permits>
            <semaphore-factory enabled="true">
                <class-name>com.acme.MySemaphoreFactory</class-name>
            </semaphore-factory>
        </semaphore>
    -->

    <!-- Add your own map merge policy implementations here:
    	<merge-policies>
           	<map-merge-policy name="MY_MERGE_POLICY">
            	<class-name>com.acme.MyOwnMergePolicy</class-name>
        	</map-merge-policy>
    	</merge-policies>
    -->



</hazelcast>



clients connect as host:port of related nodes which are up.




Next matter is how to properly store data.

Right now the implementation stores Human and DN cascades any cascades on HBase.

The problems include:

HC maps send they key and value, but JPA needs key(ID), data type(.class for fetching by id) and value.

One approach is where there are many maps on HC and same MapStore implementation.
i.e. it is practical to enter new entries for entities on hazelcast.xml per entity, but not write a different map store for each.
If MapStore implements a super class and NoSQL entity lifecycle listeners (e.g. NSHuman) this might be a bit easy.
But still, too much of coding for a single new entity. Bean, NS<Bean>,Hazelcaset<Bean>MapStore.
Why we cannot have a one big map is keys for say, Human and HumansAuthentication will be same, i.e. HumanId.

We can also store Pair<Key,Classname> as key and Bean as value.
This means a huge single HC Map with different value types.
Generic, but a salad. No fine tuning of map sizes.
See, while HBase stores data, HC will be caching a healthy amount.
We will lose the granularity if we go for one generic map.



Can try putting persistence.xml on classpath of HC and just bundling ilikeplaces-classes.jar since MapStore impl is in it anyway.
i.e. get rid of mapstore jar.







